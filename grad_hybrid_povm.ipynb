{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math as m\n",
    "import numpy as np\n",
    "import sympy as sym\n",
    "import random as rand\n",
    "import matplotlib.pyplot as plt\n",
    "import cmath as cm\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from itertools import product\n",
    "import cmath as cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defininf the states\n",
    "# defininsg coefficeients sybols\n",
    "\n",
    "def Creating_states(coeff, abstract = False):    # coeff list like [a0,a1,b0,b1]\n",
    "    if abstract == True:\n",
    "        a0 = sym.symbols('a0')\n",
    "        a1 = sym.symbols('a1')\n",
    "        b0 = sym.symbols('b0')\n",
    "        b1 = sym.symbols('b1')\n",
    "    else:\n",
    "        a0 = coeff[0]\n",
    "        a1 = coeff[1]\n",
    "        b0 = coeff[2]\n",
    "        b1 = coeff[3]\n",
    "    psi0 = [a0,a1]      # defining states\n",
    "    psi1 = [b0,b1]\n",
    "    return([psi0,psi1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polar(z):\n",
    "    real_part = z.real\n",
    "    imaginary_part = z.imag\n",
    "    r = np.sqrt(real_part**2 + imaginary_part**2)\n",
    "    theta = np.arctan(imaginary_part/real_part)\n",
    "    return r,theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def roundc(c, digits):\n",
    "    if c.imag == 0:\n",
    "        return round(c.real, digits)\n",
    "    else:\n",
    "        return round(c.real, digits) + round(c.imag, digits) * 1j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lr(lr, i):\n",
    "    return lr/(i+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the SIC POVM matrices\n",
    "w = m.e**((2/3)*m.pi*(1j))\n",
    "POVM_vec = (1/(2**.5))*(np.array([[0,1,-1],[-1,0,1],[1,-1,0],[0,w,-w**2],[-1,0,w**2],[1,-w,0],[0,w**2,-w],[-1,0,w],[1,-w**2,0]]))  # an array of POVM direction vectors\n",
    "POVM_elts = [(1/3)*np.outer(np.conjugate(POVM_vec[i]),POVM_vec[i]) for i in range(len(POVM_vec))]   # a list of POVM matrix\n",
    "\n",
    "M = [[np.trace(np.dot(POVM_elts[i],POVM_elts[j])) for i in range(len(POVM_elts))] for j in range(len(POVM_elts))]     # creating M matrix using POVM definition\n",
    "\n",
    "u_0 = [1/3 for i in range(9)]           # cerating u_0 vector, to create the inverse matrix\n",
    "M_inv = 3*np.outer(u_0,u_0) + 12*(np.eye(9) - np.outer(u_0,u_0))        # creating the inverse matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnj_vec(N, coeff, priors, POVM_elts):\n",
    "\n",
    "    initial_states = Creating_states(coeff = coeff, abstract=False)     # Creating the two states with these coefficients\n",
    "    psi0 = initial_states[0]\n",
    "    psi1 = initial_states[1]    # created the states to be discriminated\n",
    "    \n",
    "    psi0sq = []\n",
    "    psi1sq = []\n",
    "    [[psi0sq.append(i*j) for i in psi0] for j in psi0]\n",
    "    [[psi1sq.append(i*j) for i in psi1] for j in psi1]   \n",
    "    psi0psi0 = [psi0sq[0], np.sqrt(psi0sq[1]**2+psi0sq[2]**2), psi0sq[3]]    \n",
    "    psi1psi1 = [psi1sq[0], np.sqrt(psi1sq[1]**(2)+psi1sq[2]**(2)), psi1sq[3]]    # creating square states\n",
    "    \n",
    "    vec_psi0psi0 = np.array(psi0psi0)     \n",
    "    vec_psi1psi1 = np.array(psi1psi1)\n",
    "    rho = priors[0]*np.outer(vec_psi0psi0, vec_psi0psi0)+ priors[1]*np.outer(vec_psi1psi1, vec_psi1psi1)     # theoretical density matrix with priors 1/2 each.\n",
    "\n",
    "    prob_vec =  [np.trace(np.dot(POVM_elts[i],rho)) for i in range(9)] \n",
    "    prob_vec = [i.real for i in prob_vec if abs(i.imag) < .01]          # cleaned up theoretical prob vector\n",
    "\n",
    "    POVM_dir_symbols = ['d1','d2','d3','d4','d5','d6','d7','d8','d9']      # symbols to indicate collapsed direction\n",
    "    #prob distribution is simply the corresponding elements of the prob_vec\n",
    "    collapse_dir_vec = rand.choices(POVM_dir_symbols, weights=prob_vec, k = N)   # choosing collapse directions with weights for N trials\n",
    "\n",
    "    nj_vec = [collapse_dir_vec.count(f'd{i+1}') for i in range(9)]\n",
    "\n",
    "    return nj_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Linear Inversion\n",
    "\n",
    "def solve_quadratic(a, b, c):\n",
    "\n",
    "    if a == 0 and c == 0:\n",
    "        sol1 = 0\n",
    "        sol2 = 0\n",
    "\n",
    "    dis = b * b - 4 * a * c \n",
    "    sqrt_val = m.sqrt(abs(dis))\n",
    "\n",
    "    if dis > 0: \n",
    "        sol1 = (-b - sqrt_val)/(2 * a)\n",
    "        sol2 = (-b + sqrt_val)/(2 * a)\n",
    "     \n",
    "    elif dis == 0: \n",
    "        sol1 = -b / (2 * a)\n",
    "        sol2 = -b / (2 * a)\n",
    "     \n",
    "    # when discriminant is less than 0\n",
    "    else:\n",
    "        sol1 = - b / (2 * a) - 1j*sqrt_val/ (2 * a)\n",
    "        sol2 = - b / (2 * a) + 1j*sqrt_val/ (2 * a)\n",
    "        \n",
    "    return sol1, sol2\n",
    "    \n",
    "    '''coefficients = np.array([a, b, c])\n",
    "    roots = np.roots(coefficients)\n",
    "    return roots'''\n",
    "\n",
    "def experiment_fid(N, coeff, priors, POVM_elts, M_inv):\n",
    "    initial_states = Creating_states(coeff = coeff, abstract=False)     # Creating the two states with these coefficients\n",
    "    psi0 = initial_states[0]\n",
    "    psi1 = initial_states[1]    # created the states to be discriminated\n",
    "\n",
    "    nj_vec = fnj_vec(N, coeff, priors, POVM_elts)\n",
    "    pj_num_vec = [i/N for i in nj_vec]                                  # numerical prob vector     \n",
    "    \n",
    "    r_vec = np.dot(M_inv,pj_num_vec)\n",
    "    \n",
    "    # constructing the rho numrical using the r_vector etc.\n",
    "    rho_num_list = [r_vec[i]*POVM_elts[i] for i in range(len(POVM_elts))]   # list of matrices, see equation 7 in Hillery notes pair_disc.pdf\n",
    "    rho_num = np.zeros_like(rho_num_list[0])\n",
    "    for matrix in rho_num_list:\n",
    "        rho_num = np.add(rho_num, matrix)       # created the numerical rho\n",
    "     \n",
    "    eigenvalues, eigenvectors = np.linalg.eig(rho_num)\n",
    "    evals = np.array([i.real for i in eigenvalues if abs(i.imag)< .001])\n",
    "    #evals = np.array([abs(i) for i in eigenvalues])\n",
    "    index = np.argmin(evals)\n",
    "    eigenvector = eigenvectors[:,index]\n",
    "\n",
    "    c00=eigenvector[0]\n",
    "    #c01=eigenvector[1]\n",
    "    c01t=eigenvector[1]/m.sqrt(2)\n",
    "    c11=eigenvector[2]\n",
    "\n",
    "    f0,f1=solve_quadratic(c00, 2*c01t, c11)\n",
    "    f0p,f1p=solve_quadratic(c11, 2*c01t, c00)\n",
    "        \n",
    "    #all possible (positive) coeffs\n",
    "    a1 = np.conj(f0)/(m.sqrt(1+ (abs(f0))**2)) \n",
    "    a2 = 1/(m.sqrt(1+ (abs(f0))**2))\n",
    "    a3 = np.conj(f0p)/(m.sqrt(1+ (abs(f0p))**2)) \n",
    "    a4 = 1/(m.sqrt(1+ (abs(f0p))**2))\n",
    "    a5 = np.conj(f1)/(m.sqrt(1+ (abs(f1))**2)) \n",
    "    a6 = 1/(m.sqrt(1+ (abs(f1))**2))\n",
    "    a7 = np.conj(f1p)/(m.sqrt(1+ (abs(f1p))**2))\n",
    "    a8 = 1/(m.sqrt(1+ (abs(f1p))**2))\n",
    "\n",
    "    #lists of all possible coeffs, including megative and complex conjugates. each sublist correspons to a \"physical sector\" \n",
    "    v12 = [a1,a2,-a1,-a2]\n",
    "    v34 = [a3,a4,-a3,-a4]\n",
    "    v56 = [a5,a6,-a5,-a6]\n",
    "    v78 = [a7,a8,-a7,-a8]\n",
    "\n",
    "    pairs12 = [[i,j] for i in v12 for j in v12 if i!=j and i!= -j]\n",
    "    #print(f'len(pairs12): {len(pairs12)}') \n",
    "    pairs34 = [[i,j] for i in v34 for j in v34 if i!=j and i!= -j]\n",
    "    #print(f'len(pairs34): {len(pairs34)}')\n",
    "    pairs56 = [[i,j] for i in v56 for j in v56 if i!=j and i!= -j] \n",
    "    #print(f'len(pairs56): {len(pairs56)}')\n",
    "    pairs78 = [[i,j] for i in v78 for j in v78 if i!=j and i!= -j]\n",
    "    #print(f'len(pairs78): {len(pairs78)}')\n",
    "\n",
    "    pairs = pairs12 + pairs34 + pairs56 + pairs78\n",
    "    \n",
    "    #all possible fidelities\n",
    "    fid_psi0 = [abs(np.vdot(i, psi0))**2 for i in pairs]\n",
    "    fid_psi1 = [abs(np.vdot(j, psi1))**2 for j in pairs]\n",
    "\n",
    "    #Create the dictionaries for the fidelities and the corresponding num wavefunctions\n",
    "    fid_psi0_dict = dict(zip(fid_psi0, pairs))\n",
    "    fid_psi1_dict = dict(zip(fid_psi1, pairs))\n",
    "    \n",
    "    #find the max fidelity and the corresponding num wavefunction\n",
    "    fid0 = max(fid_psi0_dict.keys())\n",
    "    psi_num0 = fid_psi0_dict[fid0]\n",
    "    fid1 = max(fid_psi1_dict.keys())\n",
    "    psi_num1 = fid_psi1_dict[fid1]\n",
    "\n",
    "\n",
    "    #extract p0 and p1 numerical from rho_num\n",
    "    psi0sqn = []\n",
    "    psi1sqn = []\n",
    "    [[psi0sqn.append(i*j) for i in psi_num0] for j in psi_num0]\n",
    "    [[psi1sqn.append(i*j) for i in psi_num1] for j in psi_num1]\n",
    "    psi0psi0n = [psi0sqn[0], np.sqrt(psi0sqn[1]**2+psi0sqn[2]**2), psi0sqn[3]]    \n",
    "    psi1psi1n = [psi1sqn[0], np.sqrt(psi1sqn[1]**(2)+psi1sqn[2]**(2)), psi1sqn[3]]    # creating square states\n",
    "    vec_psi0psi0n = np.array(psi0psi0n)     \n",
    "    vec_psi1psi1n = np.array(psi1psi1n)\n",
    "\n",
    "    p0c = (np.vdot(vec_psi0psi0n,rho_num @ vec_psi0psi0n) - (abs(np.vdot(vec_psi0psi0n,vec_psi1psi1n)))**2)/(1-(abs(np.vdot(vec_psi0psi0n,vec_psi1psi1n)))**2)\n",
    "    #p1 = (np.vdot(vec_psi1psi1n,rho_num @ vec_psi1psi1n) - (abs(np.vdot(vec_psi0psi0n,vec_psi1psi1n)))**2)/(1-(abs(np.vdot(vec_psi0psi0n,vec_psi1psi1n)))**2)\n",
    "    \n",
    "    p0 = abs(p0c)\n",
    "\n",
    "    #print(f'p0: {p0}')\n",
    "    #print(f'fid0: {fid0}, fid1: {fid1}')\n",
    "    #print(f'psi_num0: {psi_num0}, psi_num1: {psi_num1}')\n",
    "\n",
    "\n",
    "    #print(p0, p1, polar(psi_num0[0]), polar(psi_num0[1]), polar(psi_num1[0]), polar(psi_num1[1]))\n",
    "\n",
    "    a = np.arccos(np.sqrt(p0)) #a = np.arcsin(np.sqrt(p1))\n",
    "    a0 = cm.polar(psi_num0[0])[0]\n",
    "    th0 = np.arccos(a0)\n",
    "    a1 = cm.polar(psi_num1[0])[0]\n",
    "    th1 = np.arccos(a1)\n",
    "    ph0 = cm.polar(psi_num0[1])[1] - cm.polar(psi_num0[0])[1]\n",
    "    ph1 = cm.polar(psi_num1[1])[1] - cm.polar(psi_num1[0])[1]\n",
    "\n",
    "    #print(f't0: {t0}, t1: {t1}')\n",
    "    #print(f'th0: {th0}, th1: {th1}')\n",
    "    #print(f'ph0: {ph0}, ph1: {ph1}')\n",
    "\n",
    "    '''th0 = th0 + np.pi\n",
    "    th1 = th1 + np.pi\n",
    "\n",
    "    prova0 = [np.cos(th0), np.sin(th0)]\n",
    "    prova1 = [np.cos(th1), np.sin(th1)]\n",
    "    print(f'fid0p: {abs(np.vdot(prova0, psi0))**2}')\n",
    "    print(f'fid1p: {abs(np.vdot(prova1, psi1))**2}')'''\n",
    "\n",
    "    return a, ph0, ph1, th0, th1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_out(a, f0, f1, t0, t1):\n",
    "\n",
    "    y_pred = torch.empty(9)\n",
    "    \n",
    "    w0 = (torch.cos(a))**2\n",
    "    w1 = (torch.sin(a))**2\n",
    "    a0 = torch.cos(t0)\n",
    "    b0 = torch.sin(t0)\n",
    "    a1 = torch.cos(t1)\n",
    "    b1 = torch.sin(t1)\n",
    "\n",
    "    n2 = torch.tensor([2.0])\n",
    "    \n",
    "    y_pred[0] = (1/6)*(w0*(b0**2)*(1 + a0**2 - 2*torch.sqrt(n2)*torch.cos(f0)*a0*b0) + w1*(b1**2)*(1 + a1**2 - 2*torch.sqrt(n2)*torch.cos(f1)*a1*b1)) #p1\n",
    "    y_pred[1] = (1/6)*(w0*(a0**2)*(1 + b0**2 - 2*torch.sqrt(n2)*torch.cos(f0)*a0*b0) + w1*(a1**2)*(1 + b1**2 - 2*torch.sqrt(n2)*torch.cos(f1)*a1*b1)) #p2\n",
    "    y_pred[2] = (1/6)*(w0*(a0**4 + b0**4 - 2*torch.cos(2*f0)*(a0**2)*(b0**2)) + w1*(a1**4 + b1**4 - 2*torch.cos(2*f1)*(a1**2)*(b1**2))) #p3\n",
    "    y_pred[3] = (1/6)*(w0*(b0**2)*(1 + a0**2 - 2*torch.sqrt(n2)*torch.cos(f0 + 2*torch.pi/3)*a0*b0) + w1*(b1**2)*(1 + a1**2 - 2*torch.sqrt(n2)*torch.cos(f1 + 2*torch.pi/3)*a1*b1)) #p4\n",
    "    y_pred[4] = (1/6)*(w0*(a0**2)*(1 + b0**2 - 2*torch.sqrt(n2)*torch.cos(f0 - 4*torch.pi/3)*a0*b0) + w1*(a1**2)*(1 + b1**2 - 2*torch.sqrt(n2)*torch.cos(f1 + 2*torch.pi/3)*a1*b1)) #p5\n",
    "    y_pred[5] = (1/6)*(w0*(a0**4 + b0**4 - 2*torch.cos(2*f0 - 2*torch.pi/3)*(a0**2)*(b0**2)) + w1*(a1**4 + b1**4 - 2*torch.cos(2*f1 - 2*torch.pi/3)*(a1**2)*(b1**2))) #p6\n",
    "    y_pred[6] = (1/6)*(w0*(b0**2)*(1 + a0**2 - 2*torch.sqrt(n2)*torch.cos(f0 - 2*torch.pi/3)*a0*b0) + w1*(b1**2)*(1 + a1**2 - 2*torch.sqrt(n2)*torch.cos(f1 - 2*torch.pi/3)*a1*b1)) #p7\n",
    "    y_pred[7] = (1/6)*(w0*(a0**2)*(1 + b0**2 - 2*torch.sqrt(n2)*torch.cos(f0 - 2*torch.pi/3)*a0*b0) + w1*(a1**2)*(1 + b1**2 - 2*torch.sqrt(n2)*torch.cos(f1 - 2*torch.pi/3)*a1*b1)) #p8\n",
    "    y_pred[8] = (1/6)*(w0*(a0**4 + b0**4 - 2*torch.cos(2*f0 - 4*torch.pi/3)*(a0**2)*(b0**2)) + w1*(a1**4 + b1**4 - 2*torch.cos(2*f1 + 2*torch.pi/3)*(a1**2)*(b1**2))) #p9\n",
    "\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def floss(ny, a, f0, f1, t0,  t1):\n",
    "    y_pred = torch_out(a, f0, f1, t0, t1)\n",
    "    total_ny = torch.sum(ny)\n",
    "    log_likelyhood = -(1/total_ny)*torch.sum(ny * torch.log(y_pred))\n",
    "    return log_likelyhood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs alpha\n",
    "\n",
    "coeff = [0**.5,1**.5,1**.5,0**.5] \n",
    "priors = [.5,.5]\n",
    "N = 1000\n",
    "\n",
    "nj_vec = fnj_vec(N, coeff, priors, POVM_elts)\n",
    "    \n",
    "nj_vec = torch.tensor(nj_vec, dtype = torch.int64)\n",
    "\n",
    "# Define your fixed values for f0, f1, t0, t1\n",
    "f0_fixed = torch.tensor([torch.pi / 2])\n",
    "f1_fixed = torch.tensor([torch.pi / 4])\n",
    "t0_fixed = torch.tensor([torch.pi / 4])\n",
    "t1_fixed = torch.tensor([torch.pi / 2])\n",
    "\n",
    "# Define the range of values for a\n",
    "a_values = torch.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "# Compute torch_out for each value of a\n",
    "torch_out_values = [torch_out(a,f0_fixed,f1_fixed,t0_fixed,t1_fixed) for a in a_values]\n",
    "floss_values = [floss(nj_vec, a, f0_fixed, f1_fixed, t0_fixed, t1_fixed) for a in a_values]\n",
    "\n",
    "# Plot the dependence of torch_out on a\n",
    "plt.plot(a_values, floss_values)\n",
    "plt.xlabel('a')\n",
    "plt.ylabel('floss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs f0\n",
    "\n",
    "coeff = [0**.5,1**.5,1**.5,0**.5] \n",
    "priors = [.5,.5]\n",
    "N = 1000\n",
    "\n",
    "nj_vec = fnj_vec(N, coeff, priors, POVM_elts)\n",
    "    \n",
    "nj_vec = torch.tensor(nj_vec, dtype = torch.int64)\n",
    "\n",
    "# Define your fixed values for a, f1, t0, t1\n",
    "a_fixed = torch.tensor([torch.pi / 4])\n",
    "f1_fixed = torch.tensor([torch.pi / 4])\n",
    "t0_fixed = torch.tensor([torch.pi / 4])\n",
    "t1_fixed = torch.tensor([torch.pi / 4])\n",
    "\n",
    "# Define the range of values for f0\n",
    "f0_values = torch.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "# Compute torch_out for each value of f0\n",
    "torch_out_values = [torch_out(a_fixed, f0, f1_fixed, t0_fixed, t1_fixed) for f0 in f0_values]\n",
    "floss_values = [floss(nj_vec, a_fixed, f0, f1_fixed, t0_fixed, t1_fixed) for f0 in f0_values]\n",
    "\n",
    "# Plot the dependence of torch_out on f0\n",
    "plt.plot(a_values, floss_values)\n",
    "plt.xlabel('f0')\n",
    "plt.ylabel('floss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss vs t0\n",
    "\n",
    "coeff = [0**.5,1**.5,1**.5,0**.5] \n",
    "priors = [.5,.5]\n",
    "N = 1000\n",
    "\n",
    "nj_vec = fnj_vec(N, coeff, priors, POVM_elts)\n",
    "    \n",
    "nj_vec = torch.tensor(nj_vec, dtype = torch.int64)\n",
    "\n",
    "# Define your fixed values for a, f0, f1, t1\n",
    "a_fixed = torch.tensor([torch.pi / 4])\n",
    "f0_fixed = torch.tensor([torch.pi / 4])\n",
    "f1_fixed = torch.tensor([torch.pi / 4])\n",
    "t1_fixed = torch.tensor([torch.pi / 4])\n",
    "\n",
    "# Define the range of values for t0\n",
    "t0_values = torch.linspace(0, 2 * np.pi, 100)\n",
    "\n",
    "# Compute torch_out for each value of t0\n",
    "torch_out_values = [torch_out(a_fixed, f0_fixed, f1_fixed, t0, t1_fixed) for t0 in t0_values]\n",
    "floss_values = [floss(nj_vec, a_fixed, f0_fixed, f1_fixed, t0, t1_fixed) for t0 in t0_values]\n",
    "\n",
    "# Plot the dependence of torch_out on t0\n",
    "plt.plot(a_values, floss_values)\n",
    "plt.xlabel('t0')\n",
    "plt.ylabel('floss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fid(learning_rate, N, coeff, priors, POVM_elts):\n",
    "\n",
    "    nj_vec = fnj_vec(N, coeff, priors, POVM_elts)\n",
    "\n",
    "    ##################################### GRADIENT DESCENT ##############################################\n",
    "    \n",
    "    nj_vec = torch.tensor(nj_vec, dtype = torch.int64)\n",
    "\n",
    "    al, f0l, f1l, t0l, t1l = experiment_fid(5000, coeff, priors, POVM_elts, M_inv)\n",
    "\n",
    "    a = torch.tensor([al], requires_grad=True)\n",
    "    f0 = torch.tensor([f0l], requires_grad=True)\n",
    "    f1 = torch.tensor([f1l], requires_grad=True)\n",
    "    t0_values = [torch.tensor([t0l], requires_grad=True)]\n",
    "    t1_values = [torch.tensor([t1l], requires_grad=True)]\n",
    "    #t0_values = [torch.tensor([t0l], requires_grad=True), torch.tensor([t0l + np.pi], requires_grad=True)]\n",
    "    #t1_values = [torch.tensor([t1l], requires_grad=True), torch.tensor([t1l + np.pi], requires_grad=True)]\n",
    "\n",
    "    initial_values = [[a], [f0], [f1], t0_values, t1_values]\n",
    "    initial_conditions = list(product(*initial_values))\n",
    "\n",
    "\n",
    "\n",
    "    # Create a list to store the loss at each epoch\n",
    "    loss_history = []\n",
    "    a_grad = []\n",
    "    f0_grad = []\n",
    "    f1_grad = []\n",
    "    t0_grad = []\n",
    "    t1_grad = []\n",
    "\n",
    "    # Run gradient descent for each initial condition\n",
    "    solutions = []\n",
    "    for ip in tqdm(initial_conditions):\n",
    "        # Set the initial condition\n",
    "        a, f0, f1, t0, t1 = ip\n",
    "        # Train for N epochs\n",
    "        for i in range(100):\n",
    "            \n",
    "            # Forward pass:\n",
    "            loss = floss(nj_vec, a, f0, f1, t0, t1)\n",
    "            # append the current loss to the history\n",
    "            loss_history.append(loss.item())\n",
    "            #print(f'Epoch {i}, Loss {loss.item()}')\n",
    "            \n",
    "\n",
    "            # Backward pass: compute gradients\n",
    "            loss.backward()\n",
    "\n",
    "            a_grad.append(a.grad.item())\n",
    "            f0_grad.append(f0.grad.item())\n",
    "            f1_grad.append(f1.grad.item())\n",
    "            t0_grad.append(t0.grad.item())\n",
    "            t1_grad.append(t1.grad.item())\n",
    "\n",
    "            # Update parameters using gradient descent\n",
    "            with torch.no_grad():\n",
    "                a -= learning_rate * a.grad\n",
    "                f0 -= learning_rate * f0.grad\n",
    "                f1 -= learning_rate * f1.grad\n",
    "                t0 -= learning_rate * t0.grad\n",
    "                t1 -= learning_rate * t1.grad\n",
    "\n",
    "            # Zero gradients for the next iteration\n",
    "            a.grad.zero_()\n",
    "            f0.grad.zero_()\n",
    "            f1.grad.zero_()\n",
    "            t0.grad.zero_()\n",
    "            t1.grad.zero_()\n",
    "\n",
    "        # Store the final solution and its loss\n",
    "        solutions.append((initial_conditions[0], loss.item()))\n",
    "        #print(f'initial conditions = {ip}')\n",
    "        #print(f'loss = {loss.item()}')\n",
    "\n",
    "    # Find the solution with the lowest loss\n",
    "    best_solution, best_loss = min(solutions, key=lambda solution: solution[1])\n",
    "\n",
    "    a, f0, f1, t0, t1 = best_solution\n",
    "    #print(f'best_solution = {best_solution}')\n",
    "    #print(f'best_loss = {best_loss}')\n",
    "\n",
    "    # after the training loop\n",
    "    plt.figure()\n",
    "    plt.plot(loss_history, label='Loss')\n",
    "    plt.plot(a_grad, label='a_grad')\n",
    "    plt.plot(f0_grad, label='f0_grad')\n",
    "    plt.plot(f1_grad, label='f1_grad')\n",
    "    plt.plot(t0_grad, label='t0_grad')\n",
    "    plt.plot(t1_grad, label='t1_grad')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend()\n",
    "    plt.show()                                  \n",
    "    \n",
    "    p0 = (torch.cos(a))**2\n",
    "    p1 = (torch.sin(a))**2\n",
    "    a0 = torch.cos(t0)\n",
    "    a1 = torch.sin(t0)\n",
    "    b0 = torch.cos(t1)\n",
    "    b1 = torch.sin(t1)\n",
    "    ph0 = torch.exp(1j*f0) #torch.cos(f0) + 1j*torch.sin(f0)\n",
    "    ph1 = torch.exp(1j*f1) #torch.cos(f1) + 1j*torch.sin(f1)\n",
    "    \n",
    "    psi0n = torch.tensor([a0, ph0*a1], dtype=torch.cdouble)\n",
    "    psi1n = torch.tensor([b0, ph1*b1], dtype=torch.cdouble)\n",
    "\n",
    "    initial_states = Creating_states(coeff = coeff, abstract=False)     # Creating the two states with these coefficients\n",
    "    psi0 = initial_states[0]\n",
    "    psi1 = initial_states[1]    # created the states to be discriminated\n",
    "    psi0p = [cm.polar(psi0[0])[0], cm.polar(psi0[1])[0]*np.exp(1j*(cm.polar(psi0[1])[1]-cm.polar(psi0[0])[1]))]\n",
    "    psi1p = [cm.polar(psi1[0])[0], cm.polar(psi1[1])[0]*np.exp(1j*(cm.polar(psi1[1])[1]-cm.polar(psi1[0])[1]))]\n",
    "    psi0t = torch.tensor(psi0p, dtype=torch.cdouble)\n",
    "    psi1t = torch.tensor(psi1p, dtype=torch.cdouble)\n",
    "\n",
    "    fid0 = torch.abs(torch.dot(psi0n, torch.conj(psi0t)))**2\n",
    "    fid1 = torch.abs(torch.dot(psi1n, torch.conj(psi1t)))**2\n",
    "\n",
    "    fid = [fid0.item(), fid1.item()]\n",
    "    p = [p0.item(), p1.item()]\n",
    "\n",
    "    return([fid,p])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#coeff = [1,0,1/(2**.5),1/(2**.5)] \n",
    "#priors = [.5,.5]\n",
    "coeff = [.9**.5,.1**.5,.1**.5,.9**.5]\n",
    "priors = [.7,.3]\n",
    "trials = [100*(i+1) for i in range(100)]\n",
    "p0trials  = [priors[0] for i in trials] \n",
    "p1trials  = [priors[1] for i in trials]\n",
    "\n",
    "lr0 = 0.01\n",
    "#ip0 = [torch.tensor([val], requires_grad=True) for val in [torch.pi / 4, 0.0, 0.0, torch.pi / 2, 0.0]]\n",
    "#print(ip0)\n",
    "#ip = [torch.tensor([torch.pi / 4], requires_grad=True),torch.tensor([0.0], requires_grad=True),torch.tensor([0.0], requires_grad=True),torch.tensor([torch.pi / 2], requires_grad=True),torch.tensor([0.0], requires_grad=True)]\n",
    "\n",
    "initial_states = Creating_states(abstract=False, coeff = coeff)     # Creating the two states with these coefficients\n",
    "psi0 = initial_states[0]\n",
    "psi1 = initial_states[1]\n",
    "\n",
    "output_f = []\n",
    "output_p = []\n",
    "\n",
    "pfid  = [1 for i in trials]    # perfect fidelity of 1\n",
    "#for i,t in tqdm(enumerate(trials)):\n",
    "    #print(f'i_N: {i}')\n",
    "    #lr = update_lr(lr0,i)\n",
    "    #ip = ip0\n",
    "    #print(f'learning rate: {lr}')\n",
    "    #output_f.append(grad_fid(lr,t,coeff,priors,POVM_elts)[0])\n",
    "    #output_p.append(grad_fid(lr,t,coeff,priors,POVM_elts)[1])\n",
    "\n",
    "output_f = [grad_fid(lr0, i, coeff, priors, POVM_elts)[0] for i in tqdm(trials)]\n",
    "output_p = [grad_fid(lr0, i, coeff, priors, POVM_elts)[1] for i in tqdm(trials)]\n",
    "\n",
    "outputf = list(map(list, zip(*output_f)))\n",
    "outputp = list(map(list, zip(*output_p)))\n",
    "\n",
    "#print(outputf)\n",
    "#print(outputp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_a, (ax1a, ax2a) = plt.subplots(1,2, figsize=(10,4), sharey=True)\n",
    "ax1a.plot(trials, outputf[0], label=r'$F_0=|\\langle \\psi_0|\\psi_0^{\\,n}\\rangle|^2$')\n",
    "ax1a.plot(trials , pfid, \"--\", label=r'$F=1$')\n",
    "ax1a.set_ylim(0.8,1)\n",
    "ax1a.set_xlabel(' N (trials)')\n",
    "ax1a.set_ylabel(r'Fidelity $F$')\n",
    "#ax1a.set_title(r'$|\\psi_0\\rangle ={}|0\\rangle+{}|1\\rangle $, $p_0={}$'.format(roundc(coeff[0],1), roundc(coeff[1],1), priors[0]))\n",
    "ax1a.legend(loc='best')\n",
    "ax2a.plot(trials, outputf[1], label=r'$F_1=|\\langle \\psi_1|\\psi_1^{\\,n}\\rangle|^2$')\n",
    "ax2a.plot(trials , pfid, \"--\", label=r'$F=1$')\n",
    "ax2a.set_ylim(0.8,1)\n",
    "ax2a.set_xlabel(' N (trials)')\n",
    "ax2a.set_ylabel(r'Fidelity $F$')\n",
    "#ax2a.set_title(r'$|\\psi_1\\rangle ={}|0\\rangle+{}|1\\rangle $, $p_1={}$'.format(roundc(coeff[2],1), roundc(coeff[3],1), priors[1]))\n",
    "ax2a.legend(loc='best')\n",
    "plt.savefig('fid.pdf')\n",
    "\n",
    " \n",
    "fig_c, (ax1c, ax2c) = plt.subplots(1,2, figsize=(10,4), sharey=True)\n",
    "ax1c.plot(trials, outputp[0], label=r'$p_{0}$ numerical')\n",
    "ax1c.plot(trials, p0trials, '--', label=r'$p_{0}$ theoretical')\n",
    "ax2c.plot(trials, outputp[1], label=r'$p_{1}$ numerical')\n",
    "ax2c.plot(trials, p1trials, '--', label=r'$p_{1}$ theoretical')\n",
    "ax1c.set_ylim(0,1)\n",
    "ax2c.set_ylim(0,1)\n",
    "ax1c.set_xlabel(' N (trials)')\n",
    "ax2c.set_xlabel(' N (trials)')\n",
    "ax1c.set_ylabel(r'Probability')\n",
    "ax2c.set_ylabel(r'Probability')\n",
    "ax1c.legend(loc='best')\n",
    "ax2c.legend(loc='best')\n",
    "#ax1c.set_title(r'$|\\psi_0\\rangle ={}|0\\rangle+{}|1\\rangle $, $p_0={}$'.format(roundc(coeff[0],1), roundc(coeff[1],1), priors[0]))\n",
    "#ax2c.set_title(r'$|\\psi_1\\rangle ={}|0\\rangle+{}|1\\rangle $, $p_1={}$'.format(roundc(coeff[2],1), roundc(coeff[3],1), priors[1]))\n",
    "plt.savefig('prior.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coeff = [1,0,0,1]\n",
    "priors = [.5,.5]\n",
    "a = 0.7609137980205711\n",
    "a = torch.tensor([a])\n",
    "t0 = 5.776511204788547\n",
    "t0 = torch.tensor([t0])\n",
    "t1 = 2.595433051560899\n",
    "t1 = torch.tensor([t1])\n",
    "f0 = 0.5205233976049031\n",
    "f0 = torch.tensor([f0])\n",
    "f1 = 0.5264971946998136\n",
    "f1 = torch.tensor([f1])\n",
    "\n",
    "p0 = (torch.cos(a))**2\n",
    "p1 = (torch.sin(a))**2\n",
    "#print('p0+p1:', p0.item()+p1.item())\n",
    "a0 = torch.cos(t0)\n",
    "a1 = torch.sin(t0)\n",
    "#print(f'a0^2 + a1^2: {(a0.item())**2 + (a1.item())**2}')\n",
    "b0 = torch.cos(t1)\n",
    "b1 = torch.sin(t1)\n",
    "#print(f'b0^2 + b1^2: {(b0.item())**2 + (b1.item())**2}')\n",
    "ph0 = torch.cos(f0) + 1j*torch.sin(f0)\n",
    "ph1 = torch.cos(f1) + 1j*torch.sin(f1)\n",
    "#print(f'p0: {p0.item()}, p1: {p1.item()}, a0: {a0.item()}, a1: {a1.item()}, b0: {b0.item()}, b1: {b1.item()}, ph0: {ph0.item()}, ph1: {ph1.item()}')\n",
    "\n",
    "psi0n = torch.tensor([a0, ph0*a1], dtype=torch.cdouble)\n",
    "psi1n = torch.tensor([b0, ph1*b1], dtype=torch.cdouble)\n",
    "initial_states = Creating_states(coeff = coeff, abstract=False)     # Creating the two states with these coefficients\n",
    "psi0 = initial_states[0]\n",
    "psi1 = initial_states[1]    # created the states to be discriminated\n",
    "psi0t = torch.tensor(psi0, dtype=torch.cdouble)\n",
    "psi1t = torch.tensor(psi1, dtype=torch.cdouble)\n",
    "\n",
    "fid0 = torch.abs(torch.dot(psi0n, torch.conj(psi0t)))**2\n",
    "fid1 = torch.abs(torch.dot(psi1n, torch.conj(psi1t)))**2\n",
    "\n",
    "fid = [fid0.item(), fid1.item()]\n",
    "p = [p0.item(), p1.item()]\n",
    "\n",
    "print(f'fid: {fid}, p: {p}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
